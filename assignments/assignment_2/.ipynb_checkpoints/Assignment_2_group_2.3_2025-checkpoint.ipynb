{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fd6b7f",
   "metadata": {},
   "source": [
    "# Assignment_2\n",
    "If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37067c",
   "metadata": {},
   "source": [
    "This assignment would evaluate tree core topics : pandas , loops  and try , continue , catch exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507ddf6",
   "metadata": {},
   "source": [
    "## Part 1. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baac9e7",
   "metadata": {},
   "source": [
    "Use the next data base `nyc_taxis.csv` , its on the github page of the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9f75d",
   "metadata": {},
   "source": [
    "Let's work with a subset of the New York City taxi trip data released by the city. We'll focus on about 90,000 yellow taxi trips to and from various NYC airports between January and June 2016. Here are some selected columns from the dataset:\n",
    "\n",
    "- `pickup_month`: the month of the trip (January is 1, December is 12)\n",
    "- `pickup_day`: the day of the month of the trip\n",
    "- `pickup_location_code`: the airport or borough where the trip started\n",
    "- `dropoff_location_code`: the airport or borough where the trip ended\n",
    "- `trip_distance`: the distance of the trip in miles\n",
    "- `trip_length`: the length of the trip in seconds\n",
    "- `fare_amount`: the base fare of the trip, in dollars\n",
    "- `total_amount`: the total amount charged to the passenger, including all fees, tolls, and tips\n",
    "\n",
    "\n",
    "Review the dictionary data [here](https://s3.amazonaws.com/dq-content/289/nyc_taxi_data_dictionary.md).\n",
    "\n",
    "Our data is stored in a CSV file called `nyc_taxis.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b81e5",
   "metadata": {},
   "source": [
    "Calculate\n",
    "1. The average distance of the trip  (`trip_distance`) for each month (`pickup_month`)\n",
    "2. The total of trips from JFK for each day of the month\n",
    "3. Calculate the average velocity according to `pickup_dayofweek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b4961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d991642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_dayofweek</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>pickup_location_code</th>\n",
       "      <th>dropoff_location_code</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_length</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fees_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2037</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.54</td>\n",
       "      <td>11.65</td>\n",
       "      <td>69.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16.29</td>\n",
       "      <td>1520</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>54.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12.70</td>\n",
       "      <td>1462</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1210</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.46</td>\n",
       "      <td>32.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.56</td>\n",
       "      <td>759</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1989</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.54</td>\n",
       "      <td>3.00</td>\n",
       "      <td>40.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19.80</td>\n",
       "      <td>2368</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17.48</td>\n",
       "      <td>2822</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.00</td>\n",
       "      <td>63.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12.76</td>\n",
       "      <td>1083</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>44.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17.54</td>\n",
       "      <td>1711</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_year  pickup_month  pickup_day  pickup_dayofweek  pickup_time  \\\n",
       "0            2016             1           1                 5            0   \n",
       "1            2016             1           1                 5            0   \n",
       "2            2016             1           1                 5            0   \n",
       "3            2016             1           1                 5            0   \n",
       "4            2016             1           1                 5            0   \n",
       "...           ...           ...         ...               ...          ...   \n",
       "2008         2016             6          30                 4            5   \n",
       "2009         2016             6          30                 4            5   \n",
       "2010         2016             6          30                 4            5   \n",
       "2011         2016             6          30                 4            5   \n",
       "2012         2016             6          30                 4            5   \n",
       "\n",
       "      pickup_location_code  dropoff_location_code  trip_distance  trip_length  \\\n",
       "0                        2                      4          21.00         2037   \n",
       "1                        2                      1          16.29         1520   \n",
       "2                        2                      6          12.70         1462   \n",
       "3                        2                      6           8.70         1210   \n",
       "4                        2                      6           5.56          759   \n",
       "...                    ...                    ...            ...          ...   \n",
       "2008                     3                      4           9.50         1989   \n",
       "2009                     2                      4          19.80         2368   \n",
       "2010                     2                      4          17.48         2822   \n",
       "2011                     2                      6          12.76         1083   \n",
       "2012                     2                      0          17.54         1711   \n",
       "\n",
       "      fare_amount  fees_amount  tolls_amount  tip_amount  total_amount  \\\n",
       "0            52.0          0.8          5.54       11.65         69.99   \n",
       "1            45.0          1.3          0.00        8.00         54.30   \n",
       "2            36.5          1.3          0.00        0.00         37.80   \n",
       "3            26.0          1.3          0.00        5.46         32.76   \n",
       "4            17.5          1.3          0.00        0.00         18.80   \n",
       "...           ...          ...           ...         ...           ...   \n",
       "2008         31.0          1.3          5.54        3.00         40.84   \n",
       "2009         52.0          0.8          5.54        0.00         58.34   \n",
       "2010         52.0          0.8          5.54        5.00         63.34   \n",
       "2011         34.5          1.3          0.00        8.95         44.75   \n",
       "2012         48.0          1.3          5.54        0.00         54.84   \n",
       "\n",
       "      payment_type  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                2  \n",
       "...            ...  \n",
       "2008             1  \n",
       "2009             1  \n",
       "2010             1  \n",
       "2011             1  \n",
       "2012             2  \n",
       "\n",
       "[2013 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = pd.read_csv(\"nyc_taxis.csv\")\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839d51aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nyc_taxis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#First we use groupby to calculate the average of the trip for each month. Take note that we don't find information about 5th month\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avg_trip_distance_per_month \u001b[38;5;241m=\u001b[39m nyc_taxis\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_month\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m avg_trip_distance_per_month\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Trip Distance (miles)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nyc_taxis' is not defined"
     ]
    }
   ],
   "source": [
    "#First we use groupby to calculate the average of the trip for each month. Take note that we don't find information about 5th month\n",
    "avg_trip_distance_per_month = nyc_taxis.groupby(\"pickup_month\")[\"trip_distance\"].mean().reset_index()\n",
    "avg_trip_distance_per_month.columns = [\"Month\", \"Average Trip Distance (miles)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_distance_per_month = df.groupby(\"pickup_month\")[\"trip_distance\"].mean().reset_index()\n",
    "avg_trip_distance_per_month.columns = [\"Month\", \"Average Trip Distance (miles)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad2565a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Average Trip Distance (miles)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  Average Trip Distance (miles)\n",
       "0  February                           3.75\n",
       "1   January                           2.75\n",
       "2     March                           3.00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_trip_distance_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "472a4c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trips from JFK Per Day of the Month:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "jfk_trips_per_day = nyc_taxis[nyc_taxis['pickup_location_code'] == 'JFK'].groupby('pickup_day').size()\n",
    "print(\"Total Trips from JFK Per Day of the Month:\")\n",
    "print(jfk_trips_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cee03ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pickup_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pickup_datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnyc_taxis.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convertir la columna de fecha (asumiendo que es una columna de tipo texto) a tipo datetime\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Crear una nueva columna para el día de la semana (0=Monday, 6=Sunday)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_dayofweek\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdayofweek\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pickup_datetime'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30aa5c1d",
   "metadata": {},
   "source": [
    "## Part 2 Loops- For loops , while loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbc99d",
   "metadata": {},
   "source": [
    "a. Using a  “for loop” and the conditional “if else” for a range bettewn 1 to 100, evaluate \"x\" so that:\n",
    "If x is a multiple of 3 print  “Fizz”\n",
    "If x is a multiple of 5 print  “Buzz”\n",
    "If x is a multiple of 3 and 5 print “FizzBuzz”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb0be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n",
      "16\n",
      "17\n",
      "Fizz\n",
      "19\n",
      "Buzz\n",
      "Fizz\n",
      "22\n",
      "23\n",
      "Fizz\n",
      "Buzz\n",
      "26\n",
      "Fizz\n",
      "28\n",
      "29\n",
      "FizzBuzz\n",
      "31\n",
      "32\n",
      "Fizz\n",
      "34\n",
      "Buzz\n",
      "Fizz\n",
      "37\n",
      "38\n",
      "Fizz\n",
      "Buzz\n",
      "41\n",
      "Fizz\n",
      "43\n",
      "44\n",
      "FizzBuzz\n",
      "46\n",
      "47\n",
      "Fizz\n",
      "49\n",
      "Buzz\n",
      "Fizz\n",
      "52\n",
      "53\n",
      "Fizz\n",
      "Buzz\n",
      "56\n",
      "Fizz\n",
      "58\n",
      "59\n",
      "FizzBuzz\n",
      "61\n",
      "62\n",
      "Fizz\n",
      "64\n",
      "Buzz\n",
      "Fizz\n",
      "67\n",
      "68\n",
      "Fizz\n",
      "Buzz\n",
      "71\n",
      "Fizz\n",
      "73\n",
      "74\n",
      "FizzBuzz\n",
      "76\n",
      "77\n",
      "Fizz\n",
      "79\n",
      "Buzz\n",
      "Fizz\n",
      "82\n",
      "83\n",
      "Fizz\n",
      "Buzz\n",
      "86\n",
      "Fizz\n",
      "88\n",
      "89\n",
      "FizzBuzz\n",
      "91\n",
      "92\n",
      "Fizz\n",
      "94\n",
      "Buzz\n",
      "Fizz\n",
      "97\n",
      "98\n",
      "Fizz\n",
      "Buzz\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 101):\n",
    "    if x % 3 == 0 and x % 5 == 0:\n",
    "        print(\"FizzBuzz\")\n",
    "    elif x % 3 == 0:\n",
    "        print(\"Fizz\")\n",
    "    elif x % 5 == 0:\n",
    "        print(\"Buzz\")\n",
    "    else:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb65bef",
   "metadata": {},
   "source": [
    "b.You are a data analyst at an online store and you have a file containing information about sales for the last year. \n",
    "\n",
    "Here are the name of the columns\n",
    "\n",
    "- `Date`: Transaction date (format: YYYY-MM-DD)\n",
    "- `Product`: Name of the product sold\n",
    "- `Quantity`: Number of units sold\n",
    "- `Price`: Unit price of the product in dollars\n",
    "- `Category`: Product Category (Electronics, Clothing, Home)\n",
    "- `Sale_ID`: A unique identifier for each transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65793b53",
   "metadata": {},
   "source": [
    "Read the `sales.csv` file using pandas:\n",
    "\n",
    "- Display the first few rows using `.head()`.\n",
    "\n",
    "Create a new column:\n",
    "- Calculate the total for each transaction (multiply `quantity` by `price`) and store it in a new column called `Total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48891912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sale_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>Home</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>Television</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Coffee Maker</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Home</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>Home</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Television</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Home</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>Desk</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Home</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>Dishwasher</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>Home</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>Bag</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>Charger</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-02-05</td>\n",
       "      <td>Chair</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>Home</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>Watch</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>3</td>\n",
       "      <td>950</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>Vacuum Cleaner</td>\n",
       "      <td>2</td>\n",
       "      <td>350</td>\n",
       "      <td>Home</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-01-04</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>Desk Lamp</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Home</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>Speaker</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Home</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          Product  Quantity  Price     Category  Sale_ID\n",
       "0   2023-01-01           Laptop         1   1000  Electronics     1001\n",
       "1   2023-01-01          T-Shirt         2     20     Clothing     1002\n",
       "2   2023-01-02  Washing Machine         1    500         Home     1003\n",
       "3   2023-01-02       Headphones         3     50  Electronics     1004\n",
       "4   2023-01-03            Pants         1     30     Clothing     1005\n",
       "5   2023-01-03       Television         1    800  Electronics     1006\n",
       "6   2023-01-04     Coffee Maker         2    100         Home     1007\n",
       "7   2023-01-05            Mouse         4     25  Electronics     1008\n",
       "8   2023-01-05             Sofa         1    700         Home     1009\n",
       "9   2023-01-06            Shoes         2     60     Clothing     1010\n",
       "10  2024-01-01           Laptop         2   1000  Electronics     2001\n",
       "11  2024-01-02       Television         1    750  Electronics     2002\n",
       "12  2024-01-03            Shirt         5     25     Clothing     2003\n",
       "13  2024-01-04     Refrigerator         1   1200         Home     2004\n",
       "14  2024-01-04         Keyboard         3     40  Electronics     2005\n",
       "15  2024-01-05             Desk         1    300         Home     2006\n",
       "16  2024-01-06          Sweater         2     50     Clothing     2007\n",
       "17  2024-02-01            Phone         1    900  Electronics     2008\n",
       "18  2024-02-02       Dishwasher         1    600         Home     2009\n",
       "19  2024-02-03              Bag         3     80     Clothing     2010\n",
       "20  2024-02-04          Charger         5     15  Electronics     2011\n",
       "21  2024-02-05            Chair         4    150         Home     2012\n",
       "22  2024-02-06            Watch         1    400     Clothing     2013\n",
       "23  2025-01-01           Laptop         3    950  Electronics     3001\n",
       "24  2025-01-02            Shoes         4     70     Clothing     3002\n",
       "25  2025-01-03   Vacuum Cleaner         2    350         Home     3003\n",
       "26  2025-01-03           Tablet         1    600  Electronics     3004\n",
       "27  2025-01-04          Sweater         3     55     Clothing     3005\n",
       "28  2025-01-05        Desk Lamp         5     30         Home     3006\n",
       "29  2025-01-06          Monitor         2    300  Electronics     3007\n",
       "30  2025-01-07           Jacket         1    200     Clothing     3008\n",
       "31  2025-01-08          Speaker         3    150  Electronics     3009\n",
       "32  2025-01-09              Bed         1   1200         Home     3010"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sales = pd.read_csv(\"sales.csv\")\n",
    "file_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c405a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sale_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Product  Quantity  Price     Category  Sale_ID\n",
       "0  2023-01-01   Laptop         1   1000  Electronics     1001\n",
       "1  2023-01-01  T-Shirt         2     20     Clothing     1002"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sales.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6ec5c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date          Product  Quantity  Price     Category  Sale_ID  Total\n",
      "0   2023-01-01           Laptop         1   1000  Electronics     1001   1000\n",
      "1   2023-01-01          T-Shirt         2     20     Clothing     1002     40\n",
      "2   2023-01-02  Washing Machine         1    500         Home     1003    500\n",
      "3   2023-01-02       Headphones         3     50  Electronics     1004    150\n",
      "4   2023-01-03            Pants         1     30     Clothing     1005     30\n",
      "5   2023-01-03       Television         1    800  Electronics     1006    800\n",
      "6   2023-01-04     Coffee Maker         2    100         Home     1007    200\n",
      "7   2023-01-05            Mouse         4     25  Electronics     1008    100\n",
      "8   2023-01-05             Sofa         1    700         Home     1009    700\n",
      "9   2023-01-06            Shoes         2     60     Clothing     1010    120\n",
      "10  2024-01-01           Laptop         2   1000  Electronics     2001   2000\n",
      "11  2024-01-02       Television         1    750  Electronics     2002    750\n",
      "12  2024-01-03            Shirt         5     25     Clothing     2003    125\n",
      "13  2024-01-04     Refrigerator         1   1200         Home     2004   1200\n",
      "14  2024-01-04         Keyboard         3     40  Electronics     2005    120\n",
      "15  2024-01-05             Desk         1    300         Home     2006    300\n",
      "16  2024-01-06          Sweater         2     50     Clothing     2007    100\n",
      "17  2024-02-01            Phone         1    900  Electronics     2008    900\n",
      "18  2024-02-02       Dishwasher         1    600         Home     2009    600\n",
      "19  2024-02-03              Bag         3     80     Clothing     2010    240\n",
      "20  2024-02-04          Charger         5     15  Electronics     2011     75\n",
      "21  2024-02-05            Chair         4    150         Home     2012    600\n",
      "22  2024-02-06            Watch         1    400     Clothing     2013    400\n",
      "23  2025-01-01           Laptop         3    950  Electronics     3001   2850\n",
      "24  2025-01-02            Shoes         4     70     Clothing     3002    280\n",
      "25  2025-01-03   Vacuum Cleaner         2    350         Home     3003    700\n",
      "26  2025-01-03           Tablet         1    600  Electronics     3004    600\n",
      "27  2025-01-04          Sweater         3     55     Clothing     3005    165\n",
      "28  2025-01-05        Desk Lamp         5     30         Home     3006    150\n",
      "29  2025-01-06          Monitor         2    300  Electronics     3007    600\n",
      "30  2025-01-07           Jacket         1    200     Clothing     3008    200\n",
      "31  2025-01-08          Speaker         3    150  Electronics     3009    450\n",
      "32  2025-01-09              Bed         1   1200         Home     3010   1200\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total for each transaction\n",
    "file_sales[\"Total\"] = file_sales[\"Quantity\"] * file_sales[\"Price\"]\n",
    "\n",
    "# Save the updated file\n",
    "file_sales.to_csv(\"file_sales_updated.csv\", index=False)\n",
    "\n",
    "print (file_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481349b",
   "metadata": {},
   "source": [
    "- Create a new DataFrame called `df_electronic` that contains only sales from the `electronics` category.\n",
    "- Calculate the total income of the `electronics` category.\n",
    "\n",
    "- Group sales by `category` and calculate the total income for each one.\n",
    "\n",
    "- Identify the product with the highest total quantity sold (`quantity`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63880c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10395\n"
     ]
    }
   ],
   "source": [
    "df_electronic = file_sales[file_sales[\"Category\"]==\"Electronics\"]\n",
    "total_income_electronic = (df_electronic[\"Quantity\"] * df_electronic[\"Price\"]).sum()\n",
    "print (total_income_electronic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94c22398",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_by_category = file_sales.groupby('Category')['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27a6a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total income by category:\n",
      " Category\n",
      "Clothing        1700\n",
      "Electronics    10395\n",
      "Home            6150\n",
      "Name: Total, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total income by category:\\n\", total_income_by_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa140aec",
   "metadata": {},
   "source": [
    "Using a for loop:\n",
    "- Print the ID of each sale (`sales_ID`) along with the total of that sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14385368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f812a0a1",
   "metadata": {},
   "source": [
    "- Display the details of all sales (ID, Product, Total) whose revenue (`total`) is greater than $500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bcfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a0b37f",
   "metadata": {},
   "source": [
    "- Using a dictionary and a `for loop`  count the total amount of products sold for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35105a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4de0def9",
   "metadata": {},
   "source": [
    "Using a while loop:\n",
    "- Accumulate the total income (Total) day by day (adds sales totals by date). Stop the loop when the accumulated revenue exceeds $1000 and print the corresponding day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd795a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5858072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa29ae57",
   "metadata": {},
   "source": [
    "- Accumulate sales totals row by row. Stop the loop when the accumulated revenue exceeds $2000 and print how many sales were necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448cc223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df07cec7",
   "metadata": {},
   "source": [
    "- Use a combination of `for and while` loops to calculate a rolling cumulative revenue:\n",
    "\n",
    "For each category, use a for loop to iterate over its transactions.\n",
    "Use a while loop to stop accumulating revenue for a category once it exceeds $ 3000.\n",
    "\n",
    "Print the cumulative revenue for each category and the number of transactions it took to exceed $3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac3914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e33b86",
   "metadata": {},
   "source": [
    "- Use a `nested for` loop to:\n",
    "\n",
    "Group the sales by year and by date.\n",
    "\n",
    "For each year, determine the date with the highest total revenue and the revenue value.\n",
    "This task requires grouping and iterating within groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff13635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15811ef9",
   "metadata": {},
   "source": [
    "## Part 3  Try, continue and catch exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff41d6",
   "metadata": {},
   "source": [
    "In this case you will work with a `students_grade.csv` dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0d1de",
   "metadata": {},
   "source": [
    "1. You are tasked with calculating the average grade for each student in the dataset. However, the dataset has some issues:\n",
    "\n",
    "Some scores are marked as \"missing\" or \"invalid\" (strings instead of numeric values).\n",
    "Some students may have incomplete grades across subjects.\n",
    "\n",
    "To calculate the average:\n",
    "\n",
    "Skip any \"invalid\" or \"missing\" values during calculations.\n",
    "If a student has no valid grades, print a warning message for that student.\n",
    "\n",
    "\n",
    "Use `try` and `except` to handle potential errors.\n",
    "Use `continue` to skip invalid rows or scores.\n",
    "Print the results in a clear format, showing the average grade for each student or a warning if no grades are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7892cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Math</th>\n",
       "      <th>English</th>\n",
       "      <th>Science</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>2014</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>2014</td>\n",
       "      <td>90</td>\n",
       "      <td>invalid</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Emily White</td>\n",
       "      <td>2014</td>\n",
       "      <td>missing</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>2014</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>missing</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Sarah Davis</td>\n",
       "      <td>2014</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>invalid</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>2014</td>\n",
       "      <td>missing</td>\n",
       "      <td>78</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Anna Lee</td>\n",
       "      <td>2014</td>\n",
       "      <td>85</td>\n",
       "      <td>missing</td>\n",
       "      <td>93</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>David Taylor</td>\n",
       "      <td>2015</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Emma Wilson</td>\n",
       "      <td>2015</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>92</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Daniel Harris</td>\n",
       "      <td>2015</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>Sophia Moore</td>\n",
       "      <td>2016</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>missing</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>James Anderson</td>\n",
       "      <td>2016</td>\n",
       "      <td>invalid</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>Olivia Thomas</td>\n",
       "      <td>2016</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>Isabella Jackson</td>\n",
       "      <td>2016</td>\n",
       "      <td>95</td>\n",
       "      <td>invalid</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>Lucas Martinez</td>\n",
       "      <td>2017</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116</td>\n",
       "      <td>Mia Garcia</td>\n",
       "      <td>2017</td>\n",
       "      <td>88</td>\n",
       "      <td>invalid</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>117</td>\n",
       "      <td>Matthew Clark</td>\n",
       "      <td>2017</td>\n",
       "      <td>missing</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>118</td>\n",
       "      <td>Charlotte Lewis</td>\n",
       "      <td>2018</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>invalid</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>119</td>\n",
       "      <td>Alexander Young</td>\n",
       "      <td>2018</td>\n",
       "      <td>invalid</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120</td>\n",
       "      <td>Amelia King</td>\n",
       "      <td>2018</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>121</td>\n",
       "      <td>Ethan Wright</td>\n",
       "      <td>2019</td>\n",
       "      <td>missing</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>122</td>\n",
       "      <td>Harper Scott</td>\n",
       "      <td>2019</td>\n",
       "      <td>94</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>123</td>\n",
       "      <td>Benjamin Green</td>\n",
       "      <td>2019</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>124</td>\n",
       "      <td>Evelyn Hall</td>\n",
       "      <td>2019</td>\n",
       "      <td>missing</td>\n",
       "      <td>invalid</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>125</td>\n",
       "      <td>Avery Adams</td>\n",
       "      <td>2020</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>126</td>\n",
       "      <td>Jackson Baker</td>\n",
       "      <td>2020</td>\n",
       "      <td>invalid</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127</td>\n",
       "      <td>Lily Nelson</td>\n",
       "      <td>2020</td>\n",
       "      <td>missing</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128</td>\n",
       "      <td>Elijah Carter</td>\n",
       "      <td>2020</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>129</td>\n",
       "      <td>Zoey Perez</td>\n",
       "      <td>2021</td>\n",
       "      <td>92</td>\n",
       "      <td>missing</td>\n",
       "      <td>invalid</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>130</td>\n",
       "      <td>Aiden Mitchell</td>\n",
       "      <td>2021</td>\n",
       "      <td>90</td>\n",
       "      <td>invalid</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>131</td>\n",
       "      <td>Layla Roberts</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>132</td>\n",
       "      <td>Owen Ramirez</td>\n",
       "      <td>2021</td>\n",
       "      <td>invalid</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>133</td>\n",
       "      <td>Hannah Walker</td>\n",
       "      <td>2022</td>\n",
       "      <td>94</td>\n",
       "      <td>missing</td>\n",
       "      <td>94</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>134</td>\n",
       "      <td>Logan Collins</td>\n",
       "      <td>2022</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>missing</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>135</td>\n",
       "      <td>Abigail Sanders</td>\n",
       "      <td>2022</td>\n",
       "      <td>missing</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>136</td>\n",
       "      <td>Jacob Edwards</td>\n",
       "      <td>2022</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>137</td>\n",
       "      <td>Scarlett Murphy</td>\n",
       "      <td>2022</td>\n",
       "      <td>invalid</td>\n",
       "      <td>invalid</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>138</td>\n",
       "      <td>Mason Barnes</td>\n",
       "      <td>2022</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>139</td>\n",
       "      <td>Aria Bell</td>\n",
       "      <td>2022</td>\n",
       "      <td>89</td>\n",
       "      <td>missing</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>140</td>\n",
       "      <td>Eleanor Fisher</td>\n",
       "      <td>2022</td>\n",
       "      <td>missing</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>141</td>\n",
       "      <td>Grayson Powell</td>\n",
       "      <td>2022</td>\n",
       "      <td>missing</td>\n",
       "      <td>88</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>142</td>\n",
       "      <td>Emily Hughes</td>\n",
       "      <td>2022</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>missing</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>143</td>\n",
       "      <td>Michael Foster</td>\n",
       "      <td>2022</td>\n",
       "      <td>missing</td>\n",
       "      <td>invalid</td>\n",
       "      <td>91</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>144</td>\n",
       "      <td>Harper Simmons</td>\n",
       "      <td>2022</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student_ID              Name  Year     Math  English  Science  History\n",
       "0          101          John Doe  2014       85       78       92       88\n",
       "1          102        Jane Smith  2014       90  invalid       87       82\n",
       "2          103       Emily White  2014  missing       89       94       85\n",
       "3          104     Michael Brown  2014       88       84  missing       79\n",
       "4          105       Sarah Davis  2014       91       87  invalid  missing\n",
       "5          106     Chris Johnson  2014  missing       78       90       81\n",
       "6          107          Anna Lee  2014       85  missing       93  missing\n",
       "7          108      David Taylor  2015       82       79       95       88\n",
       "8          109       Emma Wilson  2015       91       86       92  invalid\n",
       "9          110     Daniel Harris  2015  missing  missing       93       89\n",
       "10         111      Sophia Moore  2016       87       85  missing       84\n",
       "11         112    James Anderson  2016  invalid       90       92       80\n",
       "12         113     Olivia Thomas  2016       92       87       94       91\n",
       "13         114  Isabella Jackson  2016       95  invalid       96       93\n",
       "14         115    Lucas Martinez  2017       90       88       97       90\n",
       "15         116        Mia Garcia  2017       88  invalid       95       91\n",
       "16         117     Matthew Clark  2017  missing       92       94       93\n",
       "17         118   Charlotte Lewis  2018       89       90  invalid  missing\n",
       "18         119   Alexander Young  2018  invalid       88       93       94\n",
       "19         120       Amelia King  2018       92       91       92       95\n",
       "20         121      Ethan Wright  2019  missing       90       89  missing\n",
       "21         122      Harper Scott  2019       94       87       92       96\n",
       "22         123    Benjamin Green  2019       88       85  missing  missing\n",
       "23         124       Evelyn Hall  2019  missing  invalid       91       92\n",
       "24         125       Avery Adams  2020       93       89       92       93\n",
       "25         126     Jackson Baker  2020  invalid       85       94       96\n",
       "26         127       Lily Nelson  2020  missing       90       93       89\n",
       "27         128     Elijah Carter  2020       94       88       96       92\n",
       "28         129        Zoey Perez  2021       92  missing  invalid       91\n",
       "29         130    Aiden Mitchell  2021       90  invalid       93       88\n",
       "30         131     Layla Roberts  2021       85       86       92       94\n",
       "31         132      Owen Ramirez  2021  invalid       88       91       93\n",
       "32         133     Hannah Walker  2022       94  missing       94  invalid\n",
       "33         134     Logan Collins  2022       88       84  missing       91\n",
       "34         135   Abigail Sanders  2022  missing       89       92  missing\n",
       "35         136     Jacob Edwards  2022       91       87       95       92\n",
       "36         137   Scarlett Murphy  2022  invalid  invalid       93       95\n",
       "37         138      Mason Barnes  2022       92       88       96       94\n",
       "38         139         Aria Bell  2022       89  missing       94       93\n",
       "39         140    Eleanor Fisher  2022  missing       90       92       91\n",
       "40         141    Grayson Powell  2022  missing       88       94       89\n",
       "41         142      Emily Hughes  2022       93       92  missing       90\n",
       "42         143    Michael Foster  2022  missing  invalid       91  missing\n",
       "43         144    Harper Simmons  2022       95       89       93       94"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_students_grade = pd.read_csv(\"students_grade.csv\")\n",
    "file_students_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc1ed058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe: Average Grade = 85.75\n",
      "Jane Smith: Average Grade = 86.33\n",
      "Emily White: Average Grade = 89.33\n",
      "Michael Brown: Average Grade = 83.67\n",
      "Sarah Davis: Average Grade = 89.00\n",
      "Chris Johnson: Average Grade = 83.00\n",
      "Anna Lee: Average Grade = 89.00\n",
      "David Taylor: Average Grade = 86.00\n",
      "Emma Wilson: Average Grade = 89.67\n",
      "Daniel Harris: Average Grade = 91.00\n",
      "Sophia Moore: Average Grade = 85.33\n",
      "James Anderson: Average Grade = 87.33\n",
      "Olivia Thomas: Average Grade = 91.00\n",
      "Isabella Jackson: Average Grade = 94.67\n",
      "Lucas Martinez: Average Grade = 91.25\n",
      "Mia Garcia: Average Grade = 91.33\n",
      "Matthew Clark: Average Grade = 93.00\n",
      "Charlotte Lewis: Average Grade = 89.50\n",
      "Alexander Young: Average Grade = 91.67\n",
      "Amelia King: Average Grade = 92.50\n",
      "Ethan Wright: Average Grade = 89.50\n",
      "Harper Scott: Average Grade = 92.25\n",
      "Benjamin Green: Average Grade = 86.50\n",
      "Evelyn Hall: Average Grade = 91.50\n",
      "Avery Adams: Average Grade = 91.75\n",
      "Jackson Baker: Average Grade = 91.67\n",
      "Lily Nelson: Average Grade = 90.67\n",
      "Elijah Carter: Average Grade = 92.50\n",
      "Zoey Perez: Average Grade = 91.50\n",
      "Aiden Mitchell: Average Grade = 90.33\n",
      "Layla Roberts: Average Grade = 89.25\n",
      "Owen Ramirez: Average Grade = 90.67\n",
      "Hannah Walker: Average Grade = 94.00\n",
      "Logan Collins: Average Grade = 87.67\n",
      "Abigail Sanders: Average Grade = 90.50\n",
      "Jacob Edwards: Average Grade = 91.25\n",
      "Scarlett Murphy: Average Grade = 94.00\n",
      "Mason Barnes: Average Grade = 92.50\n",
      "Aria Bell: Average Grade = 92.00\n",
      "Eleanor Fisher: Average Grade = 91.00\n",
      "Grayson Powell: Average Grade = 90.33\n",
      "Emily Hughes: Average Grade = 91.67\n",
      "Michael Foster: Average Grade = 91.00\n",
      "Harper Simmons: Average Grade = 92.75\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar los promedios\n",
    "student_averages = {}\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for index, row in file_students_grade.iterrows():\n",
    "    student_name = row[\"Name\"]  # Obtener el nombre del estudiante\n",
    "    grades = []\n",
    "    \n",
    "    # Iterar sobre las materias\n",
    "    for subject in [\"Math\", \"English\", \"Science\", \"History\"]:\n",
    "        try:\n",
    "            grade = float(row[subject])  # Intentar convertir la calificación a número\n",
    "            grades.append(grade)  # Agregar calificación válida\n",
    "        except (ValueError, TypeError):  # Capturar errores si el valor no es numérico\n",
    "            continue  # Omitir el valor inválido y continuar\n",
    "\n",
    "    # Calcular el promedio si hay calificaciones válidas\n",
    "    if grades:\n",
    "        student_averages[student_name] = sum(grades) / len(grades)\n",
    "    else:\n",
    "        print(f\"Warning: {student_name} has no valid grades.\")  # Mensaje de advertencia\n",
    "\n",
    "# Mostrar los resultados\n",
    "for student, avg in student_averages.items():\n",
    "    print(f\"{student}: Average Grade = {avg:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5de24",
   "metadata": {},
   "source": [
    "2. Calculate the average grade per subject for each year.\n",
    "Handle invalid or missing values during the calculation by skipping them.\n",
    "Print the averages in a clean format (e.g., table or grouped output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cc466f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Grades Per Year:\n",
      "\n",
      "Year   Math       English    Science    History   \n",
      "--------------------------------------------------\n",
      "2014   87.80      83.20      91.20      83.00\n",
      "2015   86.50      82.50      93.33      88.50\n",
      "2016   91.33      87.33      94.00      87.00\n",
      "2017   89.00      90.00      95.33      91.33\n",
      "2018   90.50      89.67      92.50      94.50\n",
      "2019   91.00      87.33      90.67      94.00\n",
      "2020   93.50      88.00      93.75      92.50\n",
      "2021   89.00      87.00      92.00      91.50\n",
      "2022   91.71      88.38      93.40      92.11\n"
     ]
    }
   ],
   "source": [
    "# Convertir columnas de calificaciones a valores numéricos, ignorando errores\n",
    "grade_columns = [\"Math\", \"English\", \"Science\", \"History\"]\n",
    "file_students_grade[grade_columns] = file_students_grade[grade_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Calcular el promedio por año, omitiendo valores nulos\n",
    "avg_per_year = file_students_grade.groupby(\"Year\")[grade_columns].mean()\n",
    "\n",
    "# Imprimir la tabla con formato\n",
    "print(\"\\nAverage Grades Per Year:\\n\")\n",
    "print(f\"{'Year':<6} {'Math':<10} {'English':<10} {'Science':<10} {'History':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for year, row in avg_per_year.iterrows():\n",
    "    print(f\"{int(year):<6} {row['Math']:.2f}      {row['English']:.2f}      {row['Science']:.2f}      {row['History']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5410d0b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1ebdb",
   "metadata": {},
   "source": [
    "3. Identify students who had an average grade of 90 or above across all years (excluding invalid/missing values).\n",
    "If a student has no valid grades, skip them with a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24a9c1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Students with an Average Grade of 90 or Above:\n",
      "\n",
      "ID     Name                 Average\n",
      "-----------------------------------\n",
      "110    Daniel Harris        91.00\n",
      "113    Olivia Thomas        91.00\n",
      "114    Isabella Jackson     94.67\n",
      "115    Lucas Martinez       91.25\n",
      "116    Mia Garcia           91.33\n",
      "117    Matthew Clark        93.00\n",
      "119    Alexander Young      91.67\n",
      "120    Amelia King          92.50\n",
      "122    Harper Scott         92.25\n",
      "124    Evelyn Hall          91.50\n",
      "125    Avery Adams          91.75\n",
      "126    Jackson Baker        91.67\n",
      "127    Lily Nelson          90.67\n",
      "128    Elijah Carter        92.50\n",
      "129    Zoey Perez           91.50\n",
      "130    Aiden Mitchell       90.33\n",
      "132    Owen Ramirez         90.67\n",
      "133    Hannah Walker        94.00\n",
      "135    Abigail Sanders      90.50\n",
      "136    Jacob Edwards        91.25\n",
      "137    Scarlett Murphy      94.00\n",
      "138    Mason Barnes         92.50\n",
      "139    Aria Bell            92.00\n",
      "140    Eleanor Fisher       91.00\n",
      "141    Grayson Powell       90.33\n",
      "142    Emily Hughes         91.67\n",
      "143    Michael Foster       91.00\n",
      "144    Harper Simmons       92.75\n"
     ]
    }
   ],
   "source": [
    "# Convertir columnas de calificaciones a valores numéricos, ignorando errores\n",
    "grade_columns = [\"Math\", \"English\", \"Science\", \"History\"]\n",
    "file_students_grade[grade_columns] = file_students_grade[grade_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Calcular el promedio de cada estudiante, ignorando valores NaN\n",
    "file_students_grade[\"Average\"] = file_students_grade[grade_columns].mean(axis=1, skipna=True)\n",
    "\n",
    "# Filtrar estudiantes con promedio >= 90\n",
    "top_students = file_students_grade[file_students_grade[\"Average\"] >= 90][[\"Student_ID\", \"Name\", \"Average\"]]\n",
    "\n",
    "# Imprimir resultados\n",
    "if top_students.empty:\n",
    "    print(\"No students have an average grade of 90 or above.\")\n",
    "else:\n",
    "    print(\"\\nStudents with an Average Grade of 90 or Above:\\n\")\n",
    "    print(f\"{'ID':<6} {'Name':<20} {'Average':<6}\")\n",
    "    print(\"-\" * 35)\n",
    "    for _, row in top_students.iterrows():\n",
    "        print(f\"{row['Student_ID']:<6} {row['Name']:<20} {row['Average']:.2f}\")\n",
    "\n",
    "# Advertir si algún estudiante no tiene notas válidas\n",
    "students_with_no_valid_grades = file_students_grade[file_students_grade[\"Average\"].isna()]\n",
    "for _, row in students_with_no_valid_grades.iterrows():\n",
    "    print(f\"Warning: {row['Name']} (ID: {row['Student_ID']}) has no valid grades and was skipped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
